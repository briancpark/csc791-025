@misc{resnet,
	title        = {Deep Residual Learning for Image Recognition},
	author       = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	year         = 2015,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.1512.03385},
	url          = {https://arxiv.org/abs/1512.03385},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences}
}
@misc{l1prune,
	title        = {Pruning Filters for Efficient ConvNets},
	author       = {Li, Hao and Kadav, Asim and Durdanovic, Igor and Samet, Hanan and Graf, Hans Peter},
	year         = 2016,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.1608.08710},
	url          = {https://arxiv.org/abs/1608.08710},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences}
}
@article{levelpruner,
	title        = {Balanced Sparsity for Efficient {DNN} Inference on {GPU}},
	author       = {Zhuliang Yao and Shijie Cao and Wencong Xiao and Chen Zhang and Lanshun Nie},
	year         = 2018,
	journal      = {CoRR},
	volume       = {abs/1811.00206},
	url          = {http://arxiv.org/abs/1811.00206},
	eprinttype   = {arXiv},
	eprint       = {1811.00206},
	timestamp    = {Sun, 21 Mar 2021 17:13:43 +0100},
	biburl       = {https://dblp.org/rec/journals/corr/abs-1811-00206.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@misc{ray,
	title        = {Ray: A Distributed Framework for Emerging AI Applications},
	author       = {Moritz, Philipp and Nishihara, Robert and Wang, Stephanie and Tumanov, Alexey and Liaw, Richard and Liang, Eric and Elibol, Melih and Yang, Zongheng and Paul, William and Jordan, Michael I. and Stoica, Ion},
	year         = 2017,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.1712.05889},
	url          = {https://arxiv.org/abs/1712.05889},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {Distributed, Parallel, and Cluster Computing (cs.DC), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences}
}
@misc{proj1-repo,
	title        = {CSC 791-025 GitHub Repository},
	howpublished = {\url{https://github.com/briancpark/csc791-025/tree/main/proj1}}
}
@misc{proj2-repo,
	title        = {CSC 791-025 GitHub Repository},
	howpublished = {\url{https://github.com/briancpark/csc791-025/tree/main/proj2}}
}
@misc{proj3-repo,
	title        = {CSC 791-025 GitHub Repository},
	howpublished = {\url{https://github.com/briancpark/csc791-025/tree/main/proj3}}
}
@misc{proj4-repo,
	title        = {CSC 791-025 GitHub Repository},
	howpublished = {\url{https://github.com/briancpark/csc791-025/tree/main/proj4}}
}
@misc{final-repo,
	title        = {CSC 791-025 GitHub Repository},
	howpublished = {\url{https://github.com/briancpark/csc791-025/tree/main/final}}
}
@software{nni,
	title        = {{Neural Network Intelligence}},
	author       = {{Microsoft}},
	year         = 2021,
	month        = 1,
	url          = {https://github.com/microsoft/nni},
	version      = {2.0}
}
@misc{arc,
	title        = {ARC: A Root Cluster for Research into Scalable Computer Systems},
	howpublished = {\url{https://arcb.csc.ncsu.edu/~mueller/cluster/arc/}}
}
@misc{m1,
	title        = {Apple Macbook Pro Specifications},
	howpublished = {\url{https://www.apple.com/macbook-pro-14-and-16/specs/}}
}
@misc{a100,
	title        = {NVIDIA A100 Datasheet},
	howpublished = {\url{https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet-nvidia-us-2188504-web.pdf}}
}
@misc{v100,
	title        = {NVIDIA V100 Datasheet},
	howpublished = {\url{https://images.nvidia.com/content/technologies/volta/pdf/volta-v100-datasheet-update-us-1165301-r5.pdf}}
}
@misc{pytorchm1,
	title        = {Introducing accelerated pytorch training on Mac},
	howpublished = {\url{https://pytorch.org/blog/introducing-accelerated-pytorch-training-on-mac/}}
}
@article{qat,
	title        = {Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference},
	author       = {Benoit Jacob and Skirmantas Kligys and Bo Chen and Menglong Zhu and Matthew Tang and Andrew G. Howard and Hartwig Adam and Dmitry Kalenichenko},
	year         = 2017,
	journal      = {CoRR},
	volume       = {abs/1712.05877},
	url          = {http://arxiv.org/abs/1712.05877},
	eprinttype   = {arXiv},
	eprint       = {1712.05877},
	timestamp    = {Thu, 27 May 2021 16:20:51 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/abs-1712-05877.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{dorefa,
	title        = {DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients},
	author       = {Shuchang Zhou and Zekun Ni and Xinyu Zhou and He Wen and Yuxin Wu and Yuheng Zou},
	year         = 2016,
	journal      = {CoRR},
	volume       = {abs/1606.06160},
	url          = {http://arxiv.org/abs/1606.06160},
	eprinttype   = {arXiv},
	eprint       = {1606.06160},
	timestamp    = {Tue, 13 Sep 2022 21:45:50 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/ZhouNZWWZ16.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{binarynn,
	title        = {BinaryNet: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1},
	author       = {Matthieu Courbariaux and Yoshua Bengio},
	year         = 2016,
	journal      = {CoRR},
	volume       = {abs/1602.02830},
	url          = {http://arxiv.org/abs/1602.02830},
	eprinttype   = {arXiv},
	eprint       = {1602.02830},
	timestamp    = {Mon, 13 Aug 2018 16:46:57 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/CourbariauxB16.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{lsq,
	title        = {Learned Step Size Quantization},
	author       = {Steven K. Esser and Jeffrey L. McKinstry and Deepika Bablani and Rathinakumar Appuswamy and Dharmendra S. Modha},
	year         = 2019,
	journal      = {CoRR},
	volume       = {abs/1902.08153},
	url          = {http://arxiv.org/abs/1902.08153},
	eprinttype   = {arXiv},
	eprint       = {1902.08153},
	timestamp    = {Tue, 21 May 2019 18:03:37 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/abs-1902-08153.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{bridges-2,
	title        = {Bridges-2: A Platform for Rapidly-Evolving and Data Intensive Research},
	author       = {Brown, Shawn T. and Buitrago, Paola and Hanna, Edward and Sanielevici, Sergiu and Scibek, Robin and Nystrom, Nicholas A.},
	year         = 2021,
	booktitle    = {Practice and Experience in Advanced Research Computing},
	location     = {Boston, MA, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {PEARC '21},
	doi          = {10.1145/3437359.3465593},
	isbn         = 9781450382922,
	url          = {https://doi.org/10.1145/3437359.3465593},
	abstract     = {Today’s landscape of computational science is evolving rapidly, with a need for new, flexible, and responsive supercomputing platforms for addressing the growing areas of artificial intelligence (AI), data analytics (DA) and convergent collaborative research. To support this community, we designed and deployed the Bridges-2 platform. Building on our highly successful Bridges supercomputer, which was a high-performance computing resource supporting new communities and complex workflows, Bridges-2 supports traditional and nontraditional research communities and applications; integrates new technologies for converged, scalable high-performance computing (HPC), AI, and data analytics; prioritizes researcher productivity and ease of use; and provides an extensible architecture for interoperation with complementary data intensive projects, campuses, and clouds. In this report, we describe Bridges-2’s hardware and configuration, user environments, and systems support and present the results of the successful Early User Program.},
	articleno    = 35,
	numpages     = 4,
	keywords     = {high performance computing, artificial intelligence, data analytics}
}
@inproceedings{optuna,
	title        = {Optuna: A Next-generation Hyperparameter Optimization Framework},
	author       = {Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
	year         = 2019,
	booktitle    = {Proceedings of the 25rd {ACM} {SIGKDD} International Conference on Knowledge Discovery and Data Mining}
}
@article{ray-tune,
	title        = {Tune: {A} Research Platform for Distributed Model Selection and Training},
	author       = {Richard Liaw and Eric Liang and Robert Nishihara and Philipp Moritz and Joseph E. Gonzalez and Ion Stoica},
	year         = 2018,
	journal      = {CoRR},
	volume       = {abs/1807.05118},
	url          = {http://arxiv.org/abs/1807.05118},
	eprinttype   = {arXiv},
	eprint       = {1807.05118},
	timestamp    = {Mon, 13 Aug 2018 16:46:04 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/abs-1807-05118.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@online{fashion-mnist,
	title        = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms},
	author       = {Han Xiao and Kashif Rasul and Roland Vollgraf},
	year         = 2017,
	date         = {2017-08-28},
	eprintclass  = {cs.LG},
	eprinttype   = {arXiv},
	eprint       = {cs.LG/1708.07747}
}
@article{cifar10,
	title        = {Learning Multiple Layers of Features from Tiny Images},
	author       = {Krizhevsky, Alex},
	year         = 2009,
	pages        = {32--33},
	url          = {https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf},
	added-at     = {2021-01-21T03:01:11.000+0100},
	biburl       = {https://www.bibsonomy.org/bibtex/2fe5248afe57647d9c85c50a98a12145c/s364315},
	interhash    = {cc2d42f2b7ef6a4e76e47d1a50c8cd86},
	intrahash    = {fe5248afe57647d9c85c50a98a12145c},
	keywords     = {},
	timestamp    = {2021-01-21T03:01:11.000+0100}
}
@inproceedings{tpe,
	title        = {Algorithms for Hyper-Parameter Optimization},
	author       = {Bergstra, James and Bardenet, R\'{e}mi and Bengio, Yoshua and K\'{e}gl, Bal\'{a}zs},
	year         = 2011,
	booktitle    = {Advances in Neural Information Processing Systems},
	publisher    = {Curran Associates, Inc.},
	volume       = 24,
	url          = {https://proceedings.neurips.cc/paper/2011/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf},
	editor       = {J. Shawe-Taylor and R. Zemel and P. Bartlett and F. Pereira and K.Q. Weinberger},
	bdsk-url-1   = {https://proceedings.neurips.cc/paper/2011/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf}
}
@article{evolution,
	title        = {Large-Scale Evolution of Image Classifiers},
	author       = {Esteban Real and Sherry Moore and Andrew Selle and Saurabh Saxena and Yutaka I. Leon{-}Suematsu and Quoc V. Le and Alex Kurakin},
	year         = 2017,
	journal      = {CoRR},
	volume       = {abs/1703.01041},
	url          = {http://arxiv.org/abs/1703.01041},
	eprinttype   = {arXiv},
	eprint       = {1703.01041},
	timestamp    = {Tue, 04 Oct 2022 16:44:59 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/RealMSSSLK17.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{hyperband,
	title        = {Efficient Hyperparameter Optimization and Infinitely Many Armed Bandits},
	author       = {Lisha Li and Kevin G. Jamieson and Giulia DeSalvo and Afshin Rostamizadeh and Ameet Talwalkar},
	year         = 2016,
	journal      = {CoRR},
	volume       = {abs/1603.06560},
	url          = {http://arxiv.org/abs/1603.06560},
	eprinttype   = {arXiv},
	eprint       = {1603.06560},
	timestamp    = {Mon, 13 Aug 2018 16:48:11 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/LiJDRT16.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{vgg,
	title        = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
	author       = {Simonyan, Karen and Zisserman, Andrew},
	year         = 2014,
	journal      = {CoRR},
	volume       = {abs/1409.1556},
	url          = {http://arxiv.org/abs/1409.1556},
	added-at     = {2016-11-19T13:14:27.000+0100},
	bibsource    = {dblp computer science bibliography, http://dblp.org},
	biburl       = {https://www.bibsonomy.org/bibtex/20ee0434e0a70b329d5518f43f1742f7a/albinzehe},
	interhash    = {4e6fa56cb7cf99400d5701543ee228de},
	intrahash    = {0ee0434e0a70b329d5518f43f1742f7a},
	keywords     = {cnn ma-zehe neuralnet},
	timestamp    = {2016-11-19T13:14:27.000+0100}
}
@inproceedings{hyperopt,
	title        = {Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures},
	author       = {Bergstra, James and Yamins, Daniel and Cox, David},
	year         = 2013,
	month        = {17--19 Jun},
	booktitle    = {Proceedings of the 30th International Conference on Machine Learning},
	publisher    = {PMLR},
	address      = {Atlanta, Georgia, USA},
	series       = {Proceedings of Machine Learning Research},
	volume       = 28,
	number       = 1,
	pages        = {115--123},
	url          = {https://proceedings.mlr.press/v28/bergstra13.html},
	editor       = {Dasgupta, Sanjoy and McAllester, David},
	pdf          = {http://proceedings.mlr.press/v28/bergstra13.pdf},
	abstract     = {Many computer vision algorithms depend on configuration settings that are typically hand-tuned in the course of evaluating the algorithm for a particular data set. While such parameter tuning is often presented as being incidental to the algorithm, correctly setting these parameter choices is frequently critical to realizing a method’s full potential. Compounding matters, these parameters often must be re-tuned when the algorithm is applied to a new problem domain, and the tuning process itself often depends on personal experience and intuition in ways that are hard to quantify or describe. Since the performance of a given technique depends on both the fundamental quality of the algorithm and the details of its tuning, it is sometimes difficult to know whether a given technique is genuinely better, or simply better tuned.     In this work, we propose a meta-modeling approach to support automated hyperparameter optimization, with the goal of providing practical tools that replace hand-tuning with a reproducible and unbiased optimization process. Our approach is to expose the underlying expression graph of how a performance metric (e.g. classification accuracy on validation examples) is computed from hyperparameters that govern not only how individual processing steps are applied, but even which processing steps are included.  A hyperparameter optimization algorithm transforms this graph into a program for optimizing that performance metric.  Our approach yields state of the art results on three disparate computer vision problems: a face-matching verification task (LFW), a face identification task (PubFig83) and an object recognition task (CIFAR-10), using a single broad class of feed-forward vision architectures.}
}
@inproceedings{sklearn_api,
	title        = {{API} design for machine learning software: experiences from the scikit-learn project},
	author       = {Lars Buitinck and Gilles Louppe and Mathieu Blondel and Fabian Pedregosa and Andreas Mueller and Olivier Grisel and Vlad Niculae and Peter Prettenhofer and Alexandre Gramfort and Jaques Grobler and Robert Layton and Jake VanderPlas and Arnaud Joly and Brian Holt and Ga{\"{e}}l Varoquaux},
	year         = 2013,
	booktitle    = {ECML PKDD Workshop: Languages for Data Mining and Machine Learning},
	pages        = {108--122}
}
@misc{distillation,
	title        = {Distilling the Knowledge in a Neural Network},
	author       = {Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
	year         = 2015,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.1503.02531},
	url          = {https://arxiv.org/abs/1503.02531},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {Machine Learning (stat.ML), Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), FOS: Computer and information sciences, FOS: Computer and information sciences}
}
@inproceedings{tvm,
	title        = {TVM: An Automated End-to-End Optimizing Compiler for Deep Learning},
	author       = {Chen, Tianqi and Moreau, Thierry and Jiang, Ziheng and Zheng, Lianmin and Yan, Eddie and Cowan, Meghan and Shen, Haichen and Wang, Leyuan and Hu, Yuwei and Ceze, Luis and Guestrin, Carlos and Krishnamurthy, Arvind},
	year         = 2018,
	booktitle    = {Proceedings of the 13th USENIX Conference on Operating Systems Design and Implementation},
	location     = {Carlsbad, CA, USA},
	publisher    = {USENIX Association},
	address      = {USA},
	series       = {OSDI'18},
	pages        = {579–594},
	isbn         = 9781931971478,
	abstract     = {There is an increasing need to bring machine learning to a wide diversity of hardware devices. Current frameworks rely on vendor-specific operator libraries and optimize for a narrow range of server-class GPUs. Deploying workloads to new platforms - such as mobile phones, embedded devices, and accelerators (e.g., FPGAs, ASICs) - requires significant manual effort. We propose TVM, a compiler that exposes graph-level and operator-level optimizations to provide performance portability to deep learning workloads across diverse hardware back-ends. TVM solves optimization challenges specific to deep learning, such as high-level operator fusion, mapping to arbitrary hardware primitives, and memory latency hiding. It also automates optimization of low-level programs to hardware characteristics by employing a novel, learning-based cost modeling method for rapid exploration of code optimizations. Experimental results show that TVM delivers performance across hardware back-ends that are competitive with state-of-the-art, hand-tuned libraries for low-power CPU, mobile GPU, and server-class GPUs. We also demonstrate TVM's ability to target new accelerator back-ends, such as the FPGA-based generic deep learning accelerator. The system is open sourced and in production use inside several major companies.},
	numpages     = 16
}
@misc{densenet,
	title        = {Densely Connected Convolutional Networks},
	author       = {Huang, Gao and Liu, Zhuang and van der Maaten, Laurens and Weinberger, Kilian Q.},
	year         = 2016,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.1608.06993},
	url          = {https://arxiv.org/abs/1608.06993},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences}
}
@article{imagenet,
	title        = {{ImageNet Large Scale Visual Recognition Challenge}},
	author       = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
	year         = 2015,
	journal      = {International Journal of Computer Vision (IJCV)},
	volume       = 115,
	number       = 3,
	pages        = {211--252},
	doi          = {10.1007/s11263-015-0816-y}
}
@inproceedings{pytorch,
	title        = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
	author       = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
	year         = 2019,
	booktitle    = {Advances in Neural Information Processing Systems},
	publisher    = {Curran Associates, Inc.},
	volume       = 32,
	pages        = {},
	url          = {https://proceedings.neurips.cc/paper/2019/file/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf},
	editor       = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett}
}
@inproceedings{torchvision,
	title        = {Torchvision the Machine-Vision Package of Torch},
	author       = {Marcel, S\'{e}bastien and Rodriguez, Yann},
	year         = 2010,
	booktitle    = {Proceedings of the 18th ACM International Conference on Multimedia},
	location     = {Firenze, Italy},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {MM '10},
	pages        = {1485–1488},
	doi          = {10.1145/1873951.1874254},
	isbn         = 9781605589336,
	url          = {https://doi.org/10.1145/1873951.1874254},
	abstract     = {This paper presents Torchvision an open source machine vision package for Torch. Torch is a machine learning library providing a series of the state-of-the-art algorithms such as Neural Networks, Support Vector Machines, Gaussian Mixture Models, Hidden Markov Models and many others. Torchvision provides additional functionalities to manipulate and process images with standard image processing algorithms. Hence, the resulting images can be used directly with the Torch machine learning algorithms as Torchvision is fully integrated with Torch. Both Torch and Torchvision are written in C++ language and are publicly available under the Free-BSD License.},
	numpages     = 4,
	keywords     = {vision, pattern recognition, open source, machine learning, face detection and recognition}
}
@article{imagenet-quick,
	title        = {100-epoch ImageNet Training with AlexNet in 24 Minutes},
	author       = {Yang You and Zhao Zhang and Cho{-}Jui Hsieh and James Demmel},
	year         = 2017,
	journal      = {CoRR},
	volume       = {abs/1709.05011},
	url          = {http://arxiv.org/abs/1709.05011},
	eprinttype   = {arXiv},
	eprint       = {1709.05011},
	timestamp    = {Thu, 04 Apr 2019 12:51:57 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/abs-1709-05011.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{xgboost,
	title        = {XGBoost: {A} Scalable Tree Boosting System},
	author       = {Tianqi Chen and Carlos Guestrin},
	year         = 2016,
	journal      = {CoRR},
	volume       = {abs/1603.02754},
	url          = {http://arxiv.org/abs/1603.02754},
	eprinttype   = {arXiv},
	eprint       = {1603.02754},
	timestamp    = {Mon, 13 Aug 2018 16:47:00 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/ChenG16.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{distillation-works,
	title        = {Does Knowledge Distillation Really Work?},
	author       = {Samuel Stanton and Pavel Izmailov and Polina Kirichenko and Alexander A. Alemi and Andrew Gordon Wilson},
	year         = 2021,
	journal      = {CoRR},
	volume       = {abs/2106.05945},
	url          = {https://arxiv.org/abs/2106.05945},
	eprinttype   = {arXiv},
	eprint       = {2106.05945},
	timestamp    = {Tue, 15 Jun 2021 16:35:15 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/abs-2106-05945.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{twitter-superresolution,
	title        = {Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network},
	author       = {Wenzhe Shi and Jose Caballero and Ferenc Husz{\'{a}}r and Johannes Totz and Andrew P. Aitken and Rob Bishop and Daniel Rueckert and Zehan Wang},
	year         = 2016,
	journal      = {CoRR},
	volume       = {abs/1609.05158},
	url          = {http://arxiv.org/abs/1609.05158},
	eprinttype   = {arXiv},
	eprint       = {1609.05158},
	timestamp    = {Mon, 13 Aug 2018 16:47:09 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/ShiCHTABRW16.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@misc{sr-pruning,
	title        = {Achieving on-Mobile Real-Time Super-Resolution with Neural Architecture and Pruning Search},
	author       = {Zhan, Zheng and Gong, Yifan and Zhao, Pu and Yuan, Geng and Niu, Wei and Wu, Yushu and Zhang, Tianyun and Jayaweera, Malith and Kaeli, David and Ren, Bin and Lin, Xue and Wang, Yanzhi},
	year         = 2021,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.2108.08910},
	url          = {https://arxiv.org/abs/2108.08910},
	copyright    = {Creative Commons Attribution 4.0 International},
	keywords     = {Image and Video Processing (eess.IV), Artificial Intelligence (cs.AI), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences}
}
@misc{issue25,
	title        = {XGen Report Issue 25},
	howpublished = {\url{https://github.com/CoCoPIE-Group/XGen-Report/issues/25}}
}
@misc{issue26,
	title        = {XGen Report Issue 26},
	howpublished = {\url{https://github.com/CoCoPIE-Group/XGen-Report/issues/26}}
}
@misc{ntire22,
	title        = {NTIRE 2022 Challenge on Efficient Super-Resolution: Methods and Results},
	author       = {Li, Yawei and Zhang, Kai and Timofte, Radu and Van Gool, Luc and Kong, Fangyuan and Li, Mingxi and Liu, Songwei and Du, Zongcai and Liu, Ding and Zhou, Chenhui and Chen, Jingyi and Han, Qingrui and Li, Zheyuan and Liu, Yingqi and Chen, Xiangyu and Cai, Haoming and Qiao, Yu and Dong, Chao and Sun, Long and Pan, Jinshan and Zhu, Yi and Zong, Zhikai and Liu, Xiaoxiao and Hui, Zheng and Yang, Tao and Ren, Peiran and Xie, Xuansong and Hua, Xian-Sheng and Wang, Yanbo and Ji, Xiaozhong and Lin, Chuming and Luo, Donghao and Tai, Ying and Wang, Chengjie and Zhang, Zhizhong and Xie, Yuan and Cheng, Shen and Luo, Ziwei and Yu, Lei and Wen, Zhihong and Wu1, Qi and Li, Youwei and Fan, Haoqiang and Sun, Jian and Liu, Shuaicheng and Huang, Yuanfei and Jin, Meiguang and Huang, Hua and Liu, Jing and Zhang, Xinjian and Wang, Yan and Long, Lingshun and Li, Gen and Zhang, Yuanfan and Cao, Zuowei and Sun, Lei and Alexander, Panaetov and Wang, Yucong and Cai, Minjie and Wang, Li and Tian, Lu and Wang, Zheyuan and Ma, Hongbing and Liu, Jie and Chen, Chao and Cai, Yidong and Tang, Jie and Wu, Gangshan and Wang, Weiran and Huang, Shirui and Lu, Honglei and Liu, Huan and Wang, Keyan and Chen, Jun and Chen, Shi and Miao, Yuchun and Huang, Zimo and Zhang, Lefei and Ayazoğlu, Mustafa and Xiong, Wei and Xiong, Chengyi and Wang, Fei and Li, Hao and Wen, Ruimian and Yang, Zhijing and Zou, Wenbin and Zheng, Weixin and Ye, Tian and Zhang, Yuncheng and Kong, Xiangzhen and Arora, Aditya and Zamir, Syed Waqas and Khan, Salman and Hayat, Munawar and Khan, Fahad Shahbaz and Ning, Dandan Gaoand Dengwen Zhouand Qian and Tang, Jingzhu and Huang, Han and Wang, Yufei and Peng, Zhangheng and Li, Haobo and Guan, Wenxue and Gong, Shenghua and Li, Xin and Liu, Jun and Wang, Wanjun and Zhou, Dengwen and Zeng, Kun and Lin, Hanjiang and Chen, Xinyu and Fang, Jinsheng},
	year         = 2022,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.2205.05675},
	url          = {https://arxiv.org/abs/2205.05675},
	copyright    = {Creative Commons Attribution 4.0 International},
	keywords     = {Computer Vision and Pattern Recognition (cs.CV), Image and Video Processing (eess.IV), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering}
}
@misc{ntire22-github,
	title        = {Solution of the NTIRE 2022 Challenge on Efficient Super-Resolution},
	howpublished = {\url{https://github.com/ofsoundof/NTIRE2022_ESR}}
}
@inproceedings{bsd,
	title        = {A Database of Human Segmented Natural Images and its Application to Evaluating Segmentation Algorithms and Measuring Ecological Statistics},
	author       = {D. Martin and C. Fowlkes and D. Tal and J. Malik},
	year         = 2001,
	month        = {July},
	booktitle    = {Proc. 8th Int'l Conf. Computer Vision},
	volume       = 2,
	pages        = {416--423}
}
@misc{ardreno640,
	title        = {CPU Monkey - Qualcomm Adreno 640},
	howpublished = {\url{https://www.cpu-monkey.com/en/igpu-qualcomm_adreno_640-264}}
}
@misc{xgen-docs,
	title        = {XGen Documentation},
	howpublished = {\url{https://xgen.cocopie.ai/v1.0.28/1_Introduction/}}
}
@misc{rdn,
	title        = {Residual Dense Network for Image Super-Resolution},
	author       = {Zhang, Yulun and Tian, Yapeng and Kong, Yu and Zhong, Bineng and Fu, Yun},
	year         = 2018,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.1802.08797},
	url          = {https://arxiv.org/abs/1802.08797},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences}
}
@misc{wdsr,
	title        = {Wide Activation for Efficient and Accurate Image Super-Resolution},
	author       = {Yu, Jiahui and Fan, Yuchen and Yang, Jianchao and Xu, Ning and Wang, Zhaowen and Wang, Xinchao and Huang, Thomas},
	year         = 2018,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.1808.08718},
	url          = {https://arxiv.org/abs/1808.08718},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {Computer Vision and Pattern Recognition (cs.CV), Graphics (cs.GR), FOS: Computer and information sciences, FOS: Computer and information sciences}
}
@misc{cocopie-xgen,
	title        = {CoCoPIE XGen: A Full-Stack AI-Oriented Optimizing Framework},
	author       = {Li, Xiaofeng and Ren, Bin and Shen, Xipeng and Wang, Yanzhi},
	year         = 2022,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.2206.10620},
	url          = {https://arxiv.org/abs/2206.10620},
	copyright    = {Creative Commons Attribution 4.0 International},
	keywords     = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Computer Vision and Pattern Recognition (cs.CV), Programming Languages (cs.PL), FOS: Computer and information sciences, FOS: Computer and information sciences}
}
@misc{iphone13promax,
	title        = {iPhone 13 Pro Max Specs},
	howpublished = {\url{https://www.apple.com/am/iphone-13-pro/specs/}}
}
@misc{torchvision-blog,
	title        = {The Devil lives in the details},
	howpublished = {\url{https://tcapelle.github.io/pytorch/fastai/2021/02/26/image_resizing.html}}
}
