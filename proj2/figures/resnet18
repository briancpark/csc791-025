digraph {
	graph [size="59.55,59.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	139727997550032 [label="
 (1, 1000)" fillcolor=darkolivegreen1]
	139727997561696 [label=AddmmBackward0]
	139727997563664 -> 139727997561696
	139727997546432 [label="fc.bias
 (1000)" fillcolor=lightblue]
	139727997546432 -> 139727997563664
	139727997563664 [label=AccumulateGrad]
	139727997562512 -> 139727997561696
	139727997562512 [label=ReshapeAliasBackward0]
	139727997563472 -> 139727997562512
	139727997563472 [label=MeanBackward1]
	139727997563760 -> 139727997563472
	139727997563760 [label=ReluBackward0]
	139727997563856 -> 139727997563760
	139727997563856 [label=AddBackward0]
	139727997563952 -> 139727997563856
	139727997563952 [label=NativeBatchNormBackward0]
	139727997564096 -> 139727997563952
	139727997564096 [label=ConvolutionBackward0]
	139727997564288 -> 139727997564096
	139727997564288 [label=ReluBackward0]
	139727997564432 -> 139727997564288
	139727997564432 [label=NativeBatchNormBackward0]
	139727997564528 -> 139727997564432
	139727997564528 [label=ConvolutionBackward0]
	139727997563904 -> 139727997564528
	139727997563904 [label=ReluBackward0]
	139727997564816 -> 139727997563904
	139727997564816 [label=AddBackward0]
	139727997561312 -> 139727997564816
	139727997561312 [label=NativeBatchNormBackward0]
	139727997561456 -> 139727997561312
	139727997561456 [label=ConvolutionBackward0]
	139727997562848 -> 139727997561456
	139727997562848 [label=ReluBackward0]
	139727997562656 -> 139727997562848
	139727997562656 [label=NativeBatchNormBackward0]
	139727997562464 -> 139727997562656
	139727997562464 [label=ConvolutionBackward0]
	139727997562272 -> 139727997562464
	139727997562272 [label=ReluBackward0]
	139727997562032 -> 139727997562272
	139727997562032 [label=AddBackward0]
	139727997561888 -> 139727997562032
	139727997561888 [label=NativeBatchNormBackward0]
	139727997563232 -> 139727997561888
	139727997563232 [label=ConvolutionBackward0]
	139727997562896 -> 139727997563232
	139727997562896 [label=ReluBackward0]
	139727997561216 -> 139727997562896
	139727997561216 [label=NativeBatchNormBackward0]
	139727997564912 -> 139727997561216
	139727997564912 [label=ConvolutionBackward0]
	139727997561984 -> 139727997564912
	139727997561984 [label=ReluBackward0]
	139727997565200 -> 139727997561984
	139727997565200 [label=AddBackward0]
	139727997565296 -> 139727997565200
	139727997565296 [label=NativeBatchNormBackward0]
	139727997565440 -> 139727997565296
	139727997565440 [label=ConvolutionBackward0]
	139727997565632 -> 139727997565440
	139727997565632 [label=ReluBackward0]
	139727997565776 -> 139727997565632
	139727997565776 [label=NativeBatchNormBackward0]
	139727997565872 -> 139727997565776
	139727997565872 [label=ConvolutionBackward0]
	139727997566064 -> 139727997565872
	139727997566064 [label=ReluBackward0]
	139727997566208 -> 139727997566064
	139727997566208 [label=AddBackward0]
	139727997566304 -> 139727997566208
	139727997566304 [label=NativeBatchNormBackward0]
	139727997566448 -> 139727997566304
	139727997566448 [label=ConvolutionBackward0]
	139727997566640 -> 139727997566448
	139727997566640 [label=ReluBackward0]
	139727997566784 -> 139727997566640
	139727997566784 [label=NativeBatchNormBackward0]
	139727997566880 -> 139727997566784
	139727997566880 [label=ConvolutionBackward0]
	139727997566256 -> 139727997566880
	139727997566256 [label=ReluBackward0]
	139727997944064 -> 139727997566256
	139727997944064 [label=AddBackward0]
	139727997944160 -> 139727997944064
	139727997944160 [label=NativeBatchNormBackward0]
	139727997944304 -> 139727997944160
	139727997944304 [label=ConvolutionBackward0]
	139727997944496 -> 139727997944304
	139727997944496 [label=ReluBackward0]
	139727997944640 -> 139727997944496
	139727997944640 [label=NativeBatchNormBackward0]
	139727997944736 -> 139727997944640
	139727997944736 [label=ConvolutionBackward0]
	139727997944928 -> 139727997944736
	139727997944928 [label=ReluBackward0]
	139727997945072 -> 139727997944928
	139727997945072 [label=AddBackward0]
	139727997945168 -> 139727997945072
	139727997945168 [label=NativeBatchNormBackward0]
	139727997945312 -> 139727997945168
	139727997945312 [label=ConvolutionBackward0]
	139727997945504 -> 139727997945312
	139727997945504 [label=ReluBackward0]
	139727997945648 -> 139727997945504
	139727997945648 [label=NativeBatchNormBackward0]
	139727997945744 -> 139727997945648
	139727997945744 [label=ConvolutionBackward0]
	139727997945120 -> 139727997945744
	139727997945120 [label=ReluBackward0]
	139727997946032 -> 139727997945120
	139727997946032 [label=AddBackward0]
	139727997946128 -> 139727997946032
	139727997946128 [label=NativeBatchNormBackward0]
	139727997946272 -> 139727997946128
	139727997946272 [label=ConvolutionBackward0]
	139727997946464 -> 139727997946272
	139727997946464 [label=ReluBackward0]
	139727997946608 -> 139727997946464
	139727997946608 [label=NativeBatchNormBackward0]
	139727997946704 -> 139727997946608
	139727997946704 [label=ConvolutionBackward0]
	139727997946080 -> 139727997946704
	139727997946080 [label=MaxPool2DWithIndicesBackward0]
	139727997946992 -> 139727997946080
	139727997946992 [label=ReluBackward0]
	139727997947088 -> 139727997946992
	139727997947088 [label=NativeBatchNormBackward0]
	139727997947184 -> 139727997947088
	139727997947184 [label=ConvolutionBackward0]
	139727997947376 -> 139727997947184
	139727997387856 [label="conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	139727997387856 -> 139727997947376
	139727997947376 [label=AccumulateGrad]
	139727997947136 -> 139727997947088
	139727997387296 [label="bn1.weight
 (64)" fillcolor=lightblue]
	139727997387296 -> 139727997947136
	139727997947136 [label=AccumulateGrad]
	139727997946800 -> 139727997947088
	139727997352304 [label="bn1.bias
 (64)" fillcolor=lightblue]
	139727997352304 -> 139727997946800
	139727997946800 [label=AccumulateGrad]
	139727997946896 -> 139727997946704
	139727997345584 [label="layer1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139727997345584 -> 139727997946896
	139727997946896 [label=AccumulateGrad]
	139727997946656 -> 139727997946608
	139727997345824 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	139727997345824 -> 139727997946656
	139727997946656 [label=AccumulateGrad]
	139727997946512 -> 139727997946608
	139727997345104 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	139727997345104 -> 139727997946512
	139727997946512 [label=AccumulateGrad]
	139727997946416 -> 139727997946272
	139727997320096 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139727997320096 -> 139727997946416
	139727997946416 [label=AccumulateGrad]
	139727997946224 -> 139727997946128
	139727997320416 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	139727997320416 -> 139727997946224
	139727997946224 [label=AccumulateGrad]
	139727997946176 -> 139727997946128
	139727997319776 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	139727997319776 -> 139727997946176
	139727997946176 [label=AccumulateGrad]
	139727997946080 -> 139727997946032
	139727997945936 -> 139727997945744
	139727997315296 [label="layer1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139727997315296 -> 139727997945936
	139727997945936 [label=AccumulateGrad]
	139727997945696 -> 139727997945648
	139727997315456 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	139727997315456 -> 139727997945696
	139727997945696 [label=AccumulateGrad]
	139727997945552 -> 139727997945648
	139727997315136 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	139727997315136 -> 139727997945552
	139727997945552 [label=AccumulateGrad]
	139727997945456 -> 139727997945312
	139727997312976 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139727997312976 -> 139727997945456
	139727997945456 [label=AccumulateGrad]
	139727997945264 -> 139727997945168
	139727997313216 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	139727997313216 -> 139727997945264
	139727997945264 [label=AccumulateGrad]
	139727997945216 -> 139727997945168
	139727997312016 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	139727997312016 -> 139727997945216
	139727997945216 [label=AccumulateGrad]
	139727997945120 -> 139727997945072
	139727997944880 -> 139727997944736
	139727997269024 [label="layer2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	139727997269024 -> 139727997944880
	139727997944880 [label=AccumulateGrad]
	139727997944688 -> 139727997944640
	139727997269344 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	139727997269344 -> 139727997944688
	139727997944688 [label=AccumulateGrad]
	139727997944544 -> 139727997944640
	139727997263584 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	139727997263584 -> 139727997944544
	139727997944544 [label=AccumulateGrad]
	139727997944448 -> 139727997944304
	139727997256464 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	139727997256464 -> 139727997944448
	139727997944448 [label=AccumulateGrad]
	139727997944256 -> 139727997944160
	139727997256704 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	139727997256704 -> 139727997944256
	139727997944256 [label=AccumulateGrad]
	139727997944208 -> 139727997944160
	139727997255824 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	139727997255824 -> 139727997944208
	139727997944208 [label=AccumulateGrad]
	139727997944112 -> 139727997944064
	139727997944112 [label=NativeBatchNormBackward0]
	139727997944832 -> 139727997944112
	139727997944832 [label=ConvolutionBackward0]
	139727997944928 -> 139727997944832
	139727997944976 -> 139727997944832
	139727997308816 [label="layer2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	139727997308816 -> 139727997944976
	139727997944976 [label=AccumulateGrad]
	139727997944400 -> 139727997944112
	139727997308096 [label="layer2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	139727997308096 -> 139727997944400
	139727997944400 [label=AccumulateGrad]
	139727997944352 -> 139727997944112
	139727997307936 [label="layer2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	139727997307936 -> 139727997944352
	139727997944352 [label=AccumulateGrad]
	139727997943968 -> 139727997566880
	139727997252880 [label="layer2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	139727997252880 -> 139727997943968
	139727997943968 [label=AccumulateGrad]
	139727997566832 -> 139727997566784
	139727997253040 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	139727997253040 -> 139727997566832
	139727997566832 [label=AccumulateGrad]
	139727997566688 -> 139727997566784
	139727997252720 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	139727997252720 -> 139727997566688
	139727997566688 [label=AccumulateGrad]
	139727997566592 -> 139727997566448
	139727999238608 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	139727999238608 -> 139727997566592
	139727997566592 [label=AccumulateGrad]
	139727997566400 -> 139727997566304
	139727999241488 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	139727999241488 -> 139727997566400
	139727997566400 [label=AccumulateGrad]
	139727997566352 -> 139727997566304
	139727999245488 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	139727999245488 -> 139727997566352
	139727997566352 [label=AccumulateGrad]
	139727997566256 -> 139727997566208
	139727997566016 -> 139727997565872
	139727997542752 [label="layer3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	139727997542752 -> 139727997566016
	139727997566016 [label=AccumulateGrad]
	139727997565824 -> 139727997565776
	139727997542832 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	139727997542832 -> 139727997565824
	139727997565824 [label=AccumulateGrad]
	139727997565680 -> 139727997565776
	139727997542432 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	139727997542432 -> 139727997565680
	139727997565680 [label=AccumulateGrad]
	139727997565584 -> 139727997565440
	139727997540272 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	139727997540272 -> 139727997565584
	139727997565584 [label=AccumulateGrad]
	139727997565392 -> 139727997565296
	139727997541552 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	139727997541552 -> 139727997565392
	139727997565392 [label=AccumulateGrad]
	139727997565344 -> 139727997565296
	139727997540112 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	139727997540112 -> 139727997565344
	139727997565344 [label=AccumulateGrad]
	139727997565248 -> 139727997565200
	139727997565248 [label=NativeBatchNormBackward0]
	139727997565968 -> 139727997565248
	139727997565968 [label=ConvolutionBackward0]
	139727997566064 -> 139727997565968
	139727997566112 -> 139727997565968
	139727997544512 [label="layer3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	139727997544512 -> 139727997566112
	139727997566112 [label=AccumulateGrad]
	139727997565536 -> 139727997565248
	139727997544272 [label="layer3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	139727997544272 -> 139727997565536
	139727997565536 [label=AccumulateGrad]
	139727997565488 -> 139727997565248
	139727997544192 [label="layer3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	139727997544192 -> 139727997565488
	139727997565488 [label=AccumulateGrad]
	139727997565104 -> 139727997564912
	139727997539552 [label="layer3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	139727997539552 -> 139727997565104
	139727997565104 [label=AccumulateGrad]
	139727997564864 -> 139727997561216
	139727997539632 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	139727997539632 -> 139727997564864
	139727997564864 [label=AccumulateGrad]
	139727997561552 -> 139727997561216
	139727997539392 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	139727997539392 -> 139727997561552
	139727997561552 [label=AccumulateGrad]
	139727997562944 -> 139727997563232
	139727997538352 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	139727997538352 -> 139727997562944
	139727997562944 [label=AccumulateGrad]
	139727997561744 -> 139727997561888
	139727997538512 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	139727997538512 -> 139727997561744
	139727997561744 [label=AccumulateGrad]
	139727997561840 -> 139727997561888
	139727997538032 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	139727997538032 -> 139727997561840
	139727997561840 [label=AccumulateGrad]
	139727997561984 -> 139727997562032
	139727997562320 -> 139727997562464
	139727997535792 [label="layer4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	139727997535792 -> 139727997562320
	139727997562320 [label=AccumulateGrad]
	139727997562560 -> 139727997562656
	139727997535872 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	139727997535872 -> 139727997562560
	139727997562560 [label=AccumulateGrad]
	139727997562752 -> 139727997562656
	139727997535712 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	139727997535712 -> 139727997562752
	139727997562752 [label=AccumulateGrad]
	139727997561504 -> 139727997561456
	139727997535072 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	139727997535072 -> 139727997561504
	139727997561504 [label=AccumulateGrad]
	139727997561360 -> 139727997561312
	139727997535152 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	139727997535152 -> 139727997561360
	139727997561360 [label=AccumulateGrad]
	139727997561792 -> 139727997561312
	139727997534832 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	139727997534832 -> 139727997561792
	139727997561792 [label=AccumulateGrad]
	139727997561264 -> 139727997564816
	139727997561264 [label=NativeBatchNormBackward0]
	139727997562368 -> 139727997561264
	139727997562368 [label=ConvolutionBackward0]
	139727997562272 -> 139727997562368
	139727997562176 -> 139727997562368
	139727997537472 [label="layer4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	139727997537472 -> 139727997562176
	139727997562176 [label=AccumulateGrad]
	139727997561408 -> 139727997561264
	139727997537392 [label="layer4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	139727997537392 -> 139727997561408
	139727997561408 [label=AccumulateGrad]
	139727997561648 -> 139727997561264
	139727997537232 [label="layer4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	139727997537232 -> 139727997561648
	139727997561648 [label=AccumulateGrad]
	139727997564720 -> 139727997564528
	139727997545232 [label="layer4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	139727997545232 -> 139727997564720
	139727997564720 [label=AccumulateGrad]
	139727997564480 -> 139727997564432
	139727997545152 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	139727997545152 -> 139727997564480
	139727997564480 [label=AccumulateGrad]
	139727997564336 -> 139727997564432
	139727997545312 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	139727997545312 -> 139727997564336
	139727997564336 [label=AccumulateGrad]
	139727997564240 -> 139727997564096
	139727997545872 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	139727997545872 -> 139727997564240
	139727997564240 [label=AccumulateGrad]
	139727997564048 -> 139727997563952
	139727997545792 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	139727997545792 -> 139727997564048
	139727997564048 [label=AccumulateGrad]
	139727997564000 -> 139727997563952
	139727997545952 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	139727997545952 -> 139727997564000
	139727997564000 [label=AccumulateGrad]
	139727997563904 -> 139727997563856
	139727997563520 -> 139727997561696
	139727997563520 [label=TBackward0]
	139727997563808 -> 139727997563520
	139727997546352 [label="fc.weight
 (1000, 512)" fillcolor=lightblue]
	139727997546352 -> 139727997563808
	139727997563808 [label=AccumulateGrad]
	139727997561696 -> 139727997550032
}
