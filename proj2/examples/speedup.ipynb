{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4934a67c-0fa5-433e-af7d-dc48f6df23eb",
   "metadata": {},
   "source": [
    "## Prerequisite\n",
    "CUDA version >= 11.0\n",
    "\n",
    "TensorRT version >= 7.2\n",
    "\n",
    "Note\n",
    "\n",
    "If you havenâ€™t installed TensorRT before or use the old version, please refer to [TensorRT Installation Guide](https://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcfbfe8-46ef-4d2c-9c7e-e10f39a407a9",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f10a006-da0e-46cf-9b0a-727d8d9757d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-09 11:38:35.897109: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-09 11:38:36.078601: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-09 11:38:36.525045: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-09 11:38:36.525097: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-09 11:38:36.525102: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TorchModel(\n",
       "  (conv1): QuantizerModuleWrapper(\n",
       "    (module): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  )\n",
       "  (conv2): QuantizerModuleWrapper(\n",
       "    (module): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  )\n",
       "  (fc1): QuantizerModuleWrapper(\n",
       "    (module): Linear(in_features=256, out_features=120, bias=True)\n",
       "  )\n",
       "  (fc2): QuantizerModuleWrapper(\n",
       "    (module): Linear(in_features=120, out_features=84, bias=True)\n",
       "  )\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       "  (relu1): QuantizerModuleWrapper(\n",
       "    (module): ReLU()\n",
       "  )\n",
       "  (relu2): QuantizerModuleWrapper(\n",
       "    (module): ReLU()\n",
       "  )\n",
       "  (relu3): QuantizerModuleWrapper(\n",
       "    (module): ReLU()\n",
       "  )\n",
       "  (relu4): QuantizerModuleWrapper(\n",
       "    (module): ReLU()\n",
       "  )\n",
       "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "from scripts.compression_mnist_model import TorchModel, device, trainer, evaluator, test_trt\n",
    "\n",
    "config_list = [{\n",
    "    'quant_types': ['input', 'weight'],\n",
    "    'quant_bits': {'input': 8, 'weight': 8},\n",
    "    'op_types': ['Conv2d']\n",
    "}, {\n",
    "    'quant_types': ['output'],\n",
    "    'quant_bits': {'output': 8},\n",
    "    'op_types': ['ReLU']\n",
    "}, {\n",
    "    'quant_types': ['input', 'weight'],\n",
    "    'quant_bits': {'input': 8, 'weight': 8},\n",
    "    'op_names': ['fc1', 'fc2']\n",
    "}]\n",
    "\n",
    "model = TorchModel().to(device)\n",
    "optimizer = SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion = F.nll_loss\n",
    "dummy_input = torch.rand(32, 1, 28, 28).to(device)\n",
    "\n",
    "from nni.algorithms.compression.pytorch.quantization import QAT_Quantizer\n",
    "quantizer = QAT_Quantizer(model, config_list, optimizer, dummy_input)\n",
    "quantizer.compress()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766cef34-bc87-4f52-89e4-cec5e1afef73",
   "metadata": {},
   "source": [
    "finetuning the model by using QAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9259922c-08df-416d-8a55-459853c45464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test loss: 0.4372, Accuracy: 8872/10000 (89%)\n",
      "Average test loss: 0.1689, Accuracy: 9497/10000 (95%)\n",
      "Average test loss: 0.0955, Accuracy: 9704/10000 (97%)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    trainer(model, optimizer, criterion)\n",
    "    evaluator(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ca2731-346f-4b91-8b65-daf36b1c69c7",
   "metadata": {},
   "source": [
    "export model and get calibration_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c04a0a0a-dabc-4f7e-a7a1-8232ff1d4426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-10-09 11:39:03] \u001b[32mModel state_dict saved to ./log/mnist_model.pth\u001b[0m\n",
      "[2022-10-09 11:39:03] \u001b[32mMask dict saved to ./log/mnist_calibration.pth\u001b[0m\n",
      "calibration_config:  {'conv1': {'weight_bits': 8, 'weight_scale': tensor([0.0032], device='cuda:0'), 'weight_zero_point': tensor([112.], device='cuda:0'), 'input_bits': 8, 'tracked_min_input': -0.4242129623889923, 'tracked_max_input': 2.821486711502075}, 'conv2': {'weight_bits': 8, 'weight_scale': tensor([0.0015], device='cuda:0'), 'weight_zero_point': tensor([107.], device='cuda:0'), 'input_bits': 8, 'tracked_min_input': 0.0, 'tracked_max_input': 9.488984107971191}, 'fc1': {'weight_bits': 8, 'weight_scale': tensor([0.0010], device='cuda:0'), 'weight_zero_point': tensor([121.], device='cuda:0'), 'input_bits': 8, 'tracked_min_input': 0.0, 'tracked_max_input': 12.623224258422852}, 'fc2': {'weight_bits': 8, 'weight_scale': tensor([0.0012], device='cuda:0'), 'weight_zero_point': tensor([118.], device='cuda:0'), 'input_bits': 8, 'tracked_min_input': 0.0, 'tracked_max_input': 14.296913146972656}, 'relu1': {'output_bits': 8, 'tracked_min_output': 0.0, 'tracked_max_output': 9.634129524230957}, 'relu2': {'output_bits': 8, 'tracked_min_output': 0.0, 'tracked_max_output': 13.036018371582031}, 'relu3': {'output_bits': 8, 'tracked_min_output': 0.0, 'tracked_max_output': 14.567360877990723}, 'relu4': {'output_bits': 8, 'tracked_min_output': 0.0, 'tracked_max_output': 9.27331829071045}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs('log', exist_ok=True)\n",
    "model_path = \"./log/mnist_model.pth\"\n",
    "calibration_path = \"./log/mnist_calibration.pth\"\n",
    "calibration_config = quantizer.export_model(model_path, calibration_path)\n",
    "\n",
    "print(\"calibration_config: \", calibration_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722542c9-bff1-459a-97ae-748fafc149f0",
   "metadata": {},
   "source": [
    "build tensorRT engine to make a real speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb72e274-f1ba-4171-9018-914b9423676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nni.compression.pytorch.quantization_speedup import ModelSpeedupTensorRT\n",
    "input_shape = (32, 1, 28, 28)\n",
    "engine = ModelSpeedupTensorRT(model, input_shape, config=calibration_config, batchsize=32)\n",
    "engine.compress()\n",
    "test_trt(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7437d379-0078-4fa6-a063-132f6674dfc3",
   "metadata": {},
   "source": [
    "Note that NNI also supports post-training quantization directly, please refer to complete examples for detail.\n",
    "\n",
    "For complete examples please refer to [the code](https://github.com/microsoft/nni/blob/7811307c240ff3e87166d48c8d012da426852838/examples/model_compress/quantization/mixed_precision_speedup_mnist.py).\n",
    "\n",
    "For more parameters about the class `TensorRTModelSpeedUp`, you can refer to [Model Compression API Reference](https://nni.readthedocs.io/en/latest/reference/compression/quantization_speedup.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSC591",
   "language": "python",
   "name": "csc591"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
