{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Pruning Quickstart\n",
    "\n",
    "Here is a three-minute video to get you started with model pruning.\n",
    "\n",
    "..  youtube:: wKh51Jnr0a8\n",
    "    :align: center\n",
    "\n",
    "Model pruning is a technique to reduce the model size and computation by reducing model weight size or intermediate state size.\n",
    "There are three common practices for pruning a DNN model:\n",
    "\n",
    "#. Pre-training a model -> Pruning the model -> Fine-tuning the pruned model\n",
    "#. Pruning a model during training (i.e., pruning aware training) -> Fine-tuning the pruned model\n",
    "#. Pruning a model -> Training the pruned model from scratch\n",
    "\n",
    "NNI supports all of the above pruning practices by working on the key pruning stage.\n",
    "Following this tutorial for a quick look at how to use NNI to prune a model in a common practice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "In this tutorial, we use a simple model and pre-trained on MNIST dataset.\n",
    "If you are familiar with defining a model and training in pytorch, you can skip directly to `Pruning Model`_.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (relu2): ReLU()\n",
      "  (relu3): ReLU()\n",
      "  (relu4): ReLU()\n",
      "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import nni\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "\n",
    "from compression_mnist_model import TorchModel, trainer, evaluator, device\n",
    "\n",
    "# define the model\n",
    "model = TorchModel().to(device)\n",
    "\n",
    "# show the model structure, note that pruner will wrap the model layer.\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test loss: 0.4876, Accuracy: 8453/10000 (85%)\n",
      "Average test loss: 0.2576, Accuracy: 9182/10000 (92%)\n",
      "Average test loss: 0.1740, Accuracy: 9460/10000 (95%)\n"
     ]
    }
   ],
   "source": [
    "# define the optimizer and criterion for pre-training\n",
    "\n",
    "optimizer = SGD(model.parameters(), 1e-2)\n",
    "criterion = F.nll_loss\n",
    "\n",
    "# pre-train and evaluate the model on MNIST dataset\n",
    "for epoch in range(3):\n",
    "    trainer(model, optimizer, criterion)\n",
    "    evaluator(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning Model\n",
    "\n",
    "Using L1NormPruner to prune the model and generate the masks.\n",
    "Usually, a pruner requires original model and ``config_list`` as its inputs.\n",
    "Detailed about how to write ``config_list`` please refer :doc:`compression config specification <../compression/compression_config_list>`.\n",
    "\n",
    "The following `config_list` means all layers whose type is `Linear` or `Conv2d` will be pruned,\n",
    "except the layer named `fc3`, because `fc3` is `exclude`.\n",
    "The final sparsity ratio for each layer is 50%. The layer named `fc3` will not be pruned.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "config_list = [{\n",
    "    'sparsity_per_layer': 0.5,\n",
    "    'op_types': ['Linear', 'Conv2d']\n",
    "}, {\n",
    "    'exclude': True,\n",
    "    'op_names': ['fc3']\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruners usually require `model` and `config_list` as input arguments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages/google/protobuf/pyext/_message.cpython-310-darwin.so, 0x0002): tried: '/Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages/google/protobuf/pyext/_message.cpython-310-darwin.so' (mach-o file, but is an incompatible architecture (have (x86_64), need (arm64e)))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnni\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpruning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m L1NormPruner\n\u001b[1;32m      2\u001b[0m pruner \u001b[38;5;241m=\u001b[39m L1NormPruner(model, config_list)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# show the wrapped model structure, `PrunerModuleWrapper` have wrapped the layers that configured in the config_list.\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/nni/nni/compression/pytorch/__init__.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Microsoft Corporation.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Licensed under the MIT license.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnni\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TorchEvaluator, LightningEvaluator, TransformersEvaluator\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspeedup\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelSpeedup\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompressor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Compressor, Pruner, Quantizer\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply_compression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m apply_compression_results\n",
      "File \u001b[0;32m~/dev/nni/nni/compression/pytorch/speedup/__init__.py:4\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Microsoft Corporation.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Licensed under the MIT license.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompressor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelSpeedup\n",
      "File \u001b[0;32m~/dev/nni/nni/compression/pytorch/speedup/compressor.py:13\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnni\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_module_graph\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnni\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmask_conflict\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fix_mask_conflict\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnni\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_module_by_name\n",
      "File \u001b[0;32m~/dev/nni/nni/common/graph_utils.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Dict\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytorch_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NodePy, NodePyIO, NodePyOP, GraphPy\n\u001b[1;32m     12\u001b[0m CLASSTYPE_KIND \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClassType\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     13\u001b[0m GETATTR_KIND \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprim::GetAttr\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/csc791/lib/python3.10/site-packages/torch/utils/tensorboard/__init__.py:12\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m LooseVersion\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m tensorboard\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwriter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FileWriter, SummaryWriter  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummary\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwriter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecord_writer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecordWriter\n",
      "File \u001b[0;32m~/miniforge3/envs/csc791/lib/python3.10/site-packages/torch/utils/tensorboard/writer.py:9\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevent_pb2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SessionLog\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevent_pb2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Event\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m event_pb2\n",
      "File \u001b[0;32m~/miniforge3/envs/csc791/lib/python3.10/site-packages/tensorboard/compat/proto/event_pb2.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m _b\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mversion_info[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28;01mlambda\u001b[39;00m x:x) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28;01mlambda\u001b[39;00m x:x\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m enum_type_wrapper\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m _descriptor\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m message \u001b[38;5;28;01mas\u001b[39;00m _message\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m reflection \u001b[38;5;28;01mas\u001b[39;00m _reflection\n",
      "File \u001b[0;32m~/miniforge3/envs/csc791/lib/python3.10/site-packages/google/protobuf/descriptor.py:47\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbinascii\u001b[39;00m\n\u001b[1;32m     46\u001b[0m   \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _message\n\u001b[1;32m     48\u001b[0m   _USE_C_DESCRIPTORS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mError\u001b[39;00m(\u001b[38;5;167;01mException\u001b[39;00m):\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages/google/protobuf/pyext/_message.cpython-310-darwin.so, 0x0002): tried: '/Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages/google/protobuf/pyext/_message.cpython-310-darwin.so' (mach-o file, but is an incompatible architecture (have (x86_64), need (arm64e)))"
     ]
    }
   ],
   "source": [
    "from nni.compression.pytorch.pruning import L1NormPruner\n",
    "pruner = L1NormPruner(model, config_list)\n",
    "\n",
    "# show the wrapped model structure, `PrunerModuleWrapper` have wrapped the layers that configured in the config_list.\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard==2.8.0\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.6.0 in /Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages (from tensorboard==2.8.0) (3.20.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages (from tensorboard==2.8.0) (2.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages (from tensorboard==2.8.0) (2.28.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages (from tensorboard==2.8.0) (1.49.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages (from tensorboard==2.8.0) (65.3.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages (from tensorboard==2.8.0) (1.2.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages (from tensorboard==2.8.0) (1.8.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages (from tensorboard==2.8.0) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages (from tensorboard==2.8.0) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages (from tensorboard==2.8.0) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages (from tensorboard==2.8.0) (1.23.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages (from tensorboard==2.8.0) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages (from tensorboard==2.8.0) (2.11.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.8.0) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.8.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.8.0) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.8.0) (1.16.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.8.0) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard==2.8.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard==2.8.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard==2.8.0) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard==2.8.0) (1.26.11)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages (from werkzeug>=0.11.15->tensorboard==2.8.0) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.8.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/briancpark/miniforge3/envs/csc791/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.8.0) (3.2.1)\n",
      "Installing collected packages: tensorboard\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.10.0\n",
      "    Uninstalling tensorboard-2.10.0:\n",
      "      Successfully uninstalled tensorboard-2.10.0\n",
      "Successfully installed tensorboard-2.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorboard==2.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pruner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# compress the model and generate the masks\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m _, masks \u001b[38;5;241m=\u001b[39m \u001b[43mpruner\u001b[49m\u001b[38;5;241m.\u001b[39mcompress()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# show the masks sparsity\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, mask \u001b[38;5;129;01min\u001b[39;00m masks\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pruner' is not defined"
     ]
    }
   ],
   "source": [
    "# compress the model and generate the masks\n",
    "_, masks = pruner.compress()\n",
    "# show the masks sparsity\n",
    "for name, mask in masks.items():\n",
    "    print(name, ' sparsity : ', '{:.2}'.format(mask['weight'].sum() / mask['weight'].numel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speedup the original model with masks, note that `ModelSpeedup` requires an unwrapped model.\n",
    "The model becomes smaller after speedup,\n",
    "and reaches a higher sparsity ratio because `ModelSpeedup` will propagate the masks across layers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pruner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# need to unwrap the model, if the model is wrapped before speedup\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpruner\u001b[49m\u001b[38;5;241m.\u001b[39m_unwrap_model()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# speedup the model, for more information about speedup, please refer :doc:`pruning_speedup`.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnni\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspeedup\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelSpeedup\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pruner' is not defined"
     ]
    }
   ],
   "source": [
    "# need to unwrap the model, if the model is wrapped before speedup\n",
    "pruner._unwrap_model()\n",
    "\n",
    "# speedup the model, for more information about speedup, please refer :doc:`pruning_speedup`.\n",
    "from nni.compression.pytorch.speedup import ModelSpeedup\n",
    "\n",
    "ModelSpeedup(model, torch.rand(3, 1, 28, 28).to(device), masks).speedup_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the model will become real smaller after speedup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning Compacted Model\n",
    "Note that if the model has been sped up, you need to re-initialize a new optimizer for fine-tuning.\n",
    "Because speedup will replace the masked big layers with dense small ones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "optimizer = SGD(model.parameters(), 1e-2)\n",
    "for epoch in range(3):\n",
    "    trainer(model, optimizer, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
